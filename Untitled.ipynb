{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d22ef1",
   "metadata": {},
   "source": [
    "### Data imputation\n",
    "You have to option in order to replace NaN values left:\n",
    "1. Get real values from official website\n",
    "2. Imputation (considering that value can not be aligned with reality completely)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90080980",
   "metadata": {},
   "source": [
    "**SetUp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63feaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install miceforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f154ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "367f5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library installation (check it out to see how it works)\n",
    "# !pip install git+https://github.com/AnotherSamWilson/miceforest.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73400b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install miceforest --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd51f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library installation (check it out to see how it works)\n",
    "# !pip install git+https://github.com/AnotherSamWilson/miceforest.git\n",
    "# !pip install miceforest --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be7598e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyarrow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNNImputer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Miceforest (MICE)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmiceforest\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmiceforest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImputationKernel\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\miceforest\\__init__.py:12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mmiceforest, Multiple Imputation by Chained Equations with LightGBM.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mhttps://github.com/AnotherSamWilson/miceforest\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ampute_data, load_kernel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImputedData\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImputedData\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImputationKernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImputationKernel\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\miceforest\\utils.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pd_DataFrame, pd_Series, pd_read_parquet\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomState\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\miceforest\\compat.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"pandas\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame \u001b[38;5;28;01mas\u001b[39;00m pd_DataFrame\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series \u001b[38;5;28;01mas\u001b[39;00m pd_Series\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_parquet \u001b[38;5;28;01mas\u001b[39;00m pd_read_parquet\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py:22\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     is_numpy_dev,\n\u001b[0;32m     20\u001b[0m     np_version_under1p21,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[0;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m     25\u001b[0m     pa_version_under3p0,\n\u001b[0;32m     26\u001b[0m     pa_version_under4p0,\n\u001b[0;32m     27\u001b[0m     pa_version_under5p0,\n\u001b[0;32m     28\u001b[0m     pa_version_under6p0,\n\u001b[0;32m     29\u001b[0m     pa_version_under7p0,\n\u001b[0;32m     30\u001b[0m     pa_version_under8p0,\n\u001b[0;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlzma\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     _pa_version \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m     11\u001b[0m     _palv \u001b[38;5;241m=\u001b[39m Version(_pa_version)\n\u001b[0;32m     12\u001b[0m     pa_version_under1p01 \u001b[38;5;241m=\u001b[39m _palv \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyarrow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Miceforest (MICE)\n",
    "import miceforest as mf\n",
    "from miceforest import ImputationKernel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# General using\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc81a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_up_count_values_df(df):\n",
    "    '''\n",
    "    Sum up:\n",
    "    - dataframe size\n",
    "    - count total values not nan\n",
    "    - count total values nan\n",
    "    '''\n",
    "    print(f'Total df values (non-numeric and numeric): {df.size}')\n",
    "    print(f'Total values (numeric): {df.select_dtypes(include=[np.number]).count().sum().sum()}')\n",
    "    print(f'Total values (numeric): {df.select_dtypes(include=[np.number]).isna().sum().sum()}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10993a12",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e664ce7",
   "metadata": {},
   "source": [
    "<u>*!!! Suggestion to use train test: with enough quantity of data*</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dab453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_imputation_knn(df):\n",
    "    col_to_test = 'HICP(%)'\n",
    "    true_values_list = []\n",
    "    imputed_values_list = []\n",
    "    \n",
    "    '''\n",
    "    KNN used\n",
    "    Made by each subgroup by 'geo' column\n",
    "    '''\n",
    "\n",
    "    groups = df.groupby('geo', group_keys=False)\n",
    "\n",
    "    def impute_group(group):\n",
    "        train, test = train_test_split(group.dropna(subset=[col_to_test]), test_size=0.2, random_state=42)\n",
    "        test_copy = test.copy()\n",
    "        missing_rows = test_copy.sample(frac=0.1).index\n",
    "        true_values = test_copy.loc[missing_rows, col_to_test]\n",
    "        test_copy.loc[missing_rows, col_to_test] = np.nan\n",
    "\n",
    "        numerical_columns = train.select_dtypes(include=[np.number]).columns\n",
    "        imp = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "        imp.fit(train[numerical_columns])\n",
    "        imputed_test = imp.transform(test_copy[numerical_columns])\n",
    "        imputed_test_df = pd.DataFrame(imputed_test, columns=numerical_columns, index=test.index)\n",
    "\n",
    "        true_values_list.extend(true_values)\n",
    "        imputed_values_list.extend(imputed_test_df.loc[missing_rows, col_to_test])\n",
    "\n",
    "        imputed_group = pd.concat([train, imputed_test_df], sort=False)\n",
    "\n",
    "        return imputed_group\n",
    "\n",
    "    imputed_df = groups.apply(impute_group).reset_index(drop=True)\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'True Values': true_values_list,\n",
    "        'Imputed Values': ['{:.1f}'.format(value) for value in imputed_values_list]\n",
    "    })\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true_values_list, imputed_values_list))\n",
    "\n",
    "    range_of_data = df['HICP(%)'].max() - df['HICP(%)'].min()\n",
    "    percentage_error = (rmse / range_of_data) * 100\n",
    "    print(f'RMSE percentage_error (min,max): {percentage_error:.2f}')\n",
    "    \n",
    "    display(comparison_df)\n",
    "\n",
    "    return imputed_df, comparison_df, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df, comparison_df, rmse = iterative_imputation_knn(df_test_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec3ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_imputation_by_lr(df, estimator_choice='BayesianRidge'):\n",
    "    \n",
    "    '''\n",
    "    Impute missing values using iterative imputer.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - estimator_choice: Either 'BayesianRidge' or 'LinearRegression'\n",
    "    \n",
    "    Returns:\n",
    "    imputed_df, comparison_df, rmse\n",
    "    '''\n",
    "     # Check estimator choice\n",
    "    if estimator_choice not in ['BayesianRidge', 'LinearRegression']:\n",
    "        raise ValueError(\"estimator_choice must be either 'BayesianRidge' or 'LinearRegression'\")\n",
    "\n",
    "    # Select column to check\n",
    "    col_to_test = 'HICP(%)'\n",
    "    \n",
    "    true_values_list = []\n",
    "    imputed_values_list = []\n",
    "    categorical_values_list = []\n",
    "\n",
    "    # Group by 'geo' column\n",
    "    groups = df.groupby('geo')\n",
    "    \n",
    "    # Model used\n",
    "    print('BayesianRidge model')\n",
    "\n",
    "    # Define a function to impute missing values within each group\n",
    "    def impute_group(group):\n",
    "        subset_group = group.dropna(subset=[col_to_test]).copy()\n",
    "        true_values = subset_group.sample(frac=0.1)[col_to_test]\n",
    "        subset_group.loc[true_values.index, col_to_test] = np.nan\n",
    "        numerical_columns = subset_group.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        if estimator_choice == 'BayesianRidge':\n",
    "            imp = IterativeImputer(estimator=BayesianRidge(), max_iter=30, random_state=0)\n",
    "        else:\n",
    "            imp = IterativeImputer(estimator=LinearRegression(), max_iter=30, random_state=0)\n",
    "            \n",
    "        subset_group[numerical_columns] = imp.fit_transform(subset_group[numerical_columns])\n",
    "        \n",
    "#         # --- 3-KNN\n",
    "#         imp = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "#         subset_group[numerical_columns] = imp.fit_transform(subset_group[numerical_columns])\n",
    "\n",
    "        for idx in true_values.index:\n",
    "            true_values_list.append(true_values[idx])\n",
    "            imputed_values_list.append(subset_group.loc[idx, col_to_test])\n",
    "            categorical_values_list.append(group.loc[idx, ['geo', 'country', 'year']])\n",
    "\n",
    "        return subset_group\n",
    "\n",
    "    imputed_df = groups.apply(impute_group).reset_index(drop=True)\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        **pd.DataFrame(categorical_values_list),\n",
    "        'True Values': true_values_list,\n",
    "        'Imputed Values': ['{:.1f}'.format(value) for value in imputed_values_list]\n",
    "    })\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true_values_list, imputed_values_list))\n",
    "    range_of_data = df[col_to_test].max() - df[col_to_test].min()\n",
    "    percentage_error = (rmse / range_of_data) * 100\n",
    "    \n",
    "    print(f'MEAN true values: {np.mean(true_values_list):.2f}')\n",
    "    print(f'MEAN imputed values: {np.mean(imputed_values_list):.2f}')\n",
    "    print(f'RMSE percentage_error (min,max): {percentage_error:.2f}')\n",
    "    \n",
    "    display(comparison_df)\n",
    "\n",
    "    return imputed_df, comparison_df, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff33172",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df, comparison_df, rmse = iterative_imputation_by_lr(df_test_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400d027",
   "metadata": {},
   "source": [
    "**<u>MICE model, following tested two approach</u>**\n",
    "* All dataset\n",
    "* Subgrouped by 'geo', for two reason:\n",
    "    * we can not removed bias from years just selecting one year caused by low data\n",
    "    * identifying more comparable countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ac039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee0ab9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def mice_train_test(X, y):\n",
    "    \n",
    "    '''\n",
    "    Steps model:\n",
    "    1) Imputation MICE for X train (saved in 'X_train_imputed')\n",
    "    2) Train LR model in 'X_train_imputed'\n",
    "    3) Imputation MICE for X test (saved in 'X_test_imputed') \n",
    "    4) predictions variable: model predict 'X_test_imputed'\n",
    "    Results beetwen y_test, predictions: rmse, r2, adjusted_r2\n",
    "    \n",
    "    ====================\n",
    "   \n",
    "    - Select original dataframe\n",
    "    - Split in: X, y\n",
    "    - test_size setted: 0.2 (suggestion to use train test: with enough quantity of data)\n",
    "    \n",
    "    Note: make sure you have enough nan value to make MICE interesting to use\n",
    "    '''\n",
    "\n",
    "    # Dividiamo i dati in training e test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Inizializziamo il kernel di miceforest per il training set\n",
    "    kernel_train = mf.ImputationKernel(X_train, save_all_iterations=True, random_state=0)\n",
    "\n",
    "    # Imputiamo i valori mancanti nel training set\n",
    "    kernel_train.mice(3)\n",
    "\n",
    "    # Recuperiamo il dataset imputato\n",
    "    X_train_imputed = kernel_train.complete_data()\n",
    "    X_train_df = pd.DataFrame(X_train_imputed)\n",
    "\n",
    "    # Addestriamo un modello sui dati imputati\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_imputed, y_train)\n",
    "\n",
    "    # Imputiamo i valori mancanti nel test set usando le stesse informazioni dal training set\n",
    "    kernel_test = mf.ImputationKernel(X_test, save_all_iterations=True, random_state=0)\n",
    "    kernel_test.mice(3)\n",
    "\n",
    "    # Recuperiamo il dataset imputato\n",
    "    X_test_imputed = kernel_test.complete_data()\n",
    "    X_test_df = pd.DataFrame(X_test_imputed)\n",
    "\n",
    "    # Root Mean Squared Error: calcoliamo l'errore quadratico medio del modello sul test set\n",
    "    predictions = model.predict(X_test_imputed)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "    # R2\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(f'R-squared: {r2}')\n",
    "\n",
    "    # R2 Adjusted\n",
    "    n = y_test.shape[0] # il numero di osservazioni\n",
    "    p = X_test.shape[1] # il numero di predittori\n",
    "\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "    print(f'Adjusted R-squared: {adjusted_r2}')\n",
    "    \n",
    "    return rmse, r2, adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c35b1f",
   "metadata": {},
   "source": [
    "<u>*!!! Suggestion to use train test: with enough quantity of data*</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69e90ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one: made by all data\n",
    "def mice_imputation_test(df, col_to_test = 'HICP(%)'):\n",
    "    '''\n",
    "    **Test Miceforest predictions**\n",
    "    \n",
    "    Select original dataframe (with nan values)\n",
    "    \n",
    "    1) Select df with original values\n",
    "    1) Select columns to test. Values of that will be randomly converted to nan and tested with predictions\n",
    "    2) All nan values predicted will be compared with real\n",
    "    \n",
    "    Note: Make sure you don't have empty values of columns: 'geo', 'country', 'year' \n",
    "    '''\n",
    "    \n",
    "    # If columns are not category yet, convert them\n",
    "    df_mf = df.copy()\n",
    "    df_mf[['geo', 'country', 'year']] = df_mf[['geo', 'country', 'year']].astype('category')\n",
    "    \n",
    "    # Crea una copia del DataFrame e seleziona una frazione dei dati noti da imputare\n",
    "    df_mf = df.dropna(subset=[col_to_test]).copy()\n",
    "    true_values = df_mf.sample(frac=0.1)[col_to_test]\n",
    "    df_mf.loc[true_values.index, col_to_test] = np.nan\n",
    "    \n",
    "    # Crea il modello MICE\n",
    "    kds = mf.ImputationKernel(df_mf, random_state=42)\n",
    "    \n",
    "    # --- Tuning parameters\n",
    "    optimal_parameters, losses = kds.tune_parameters(dataset=0, optimization_steps=10)\n",
    "    kds.mice(1, variable_parameters=optimal_parameters)\n",
    "#     print(optimal_parameters)\n",
    "    # ---\n",
    "    \n",
    "    # --- Manual setting\n",
    "    # n_estimators, are number of tree. So, define it considering how mauch data your df contains\n",
    "#     kds.mice(iterations=20, n_estimators=10, device='gpu') # verbose=2\n",
    "\n",
    "    # Completa i dati imputati\n",
    "    imputed_df = kds.complete_data()\n",
    "\n",
    "    # Recupera i valori imputati\n",
    "    imputed_values = imputed_df.loc[true_values.index, col_to_test]\n",
    "\n",
    "    # Calcola l'RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, imputed_values))\n",
    "\n",
    "    # Calcola l'errore percentuale\n",
    "    range_of_data = df[col_to_test].max() - df[col_to_test].min()\n",
    "    percentage_error = (rmse / range_of_data) * 100\n",
    "    print(f'RMSE percentage_error (min,max): {percentage_error:.2f}')\n",
    "\n",
    "    # Crea un DataFrame con i valori reali e imputati\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'True Values': true_values,\n",
    "        'Imputed Values': ['{:.1f}'.format(value) for value in imputed_values]\n",
    "    })\n",
    "    \n",
    "    display(comparison_df)\n",
    "\n",
    "    return imputed_df, comparison_df, rmse, kds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d664f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataframe (df_test_rep)\n",
    "imputed_df, comparison_df, rmse, kds = mice_imputation_test(df_test_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot compare the distribution by data and data with imputation\n",
    "kds.plot_imputed_distributions(wspace=0.2,hspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855626fc",
   "metadata": {},
   "source": [
    "<u>Model (use 'geo' reference)</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab3b5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test two: made by each 'geo'\n",
    "def mice_forest_geo(df, col_to_test='HICP(%)', geo_column='geo', country_column='country'):\n",
    "    \n",
    "    '''\n",
    "    This function allows to impute the missing data in a dataframe taking into account\n",
    "    the subgroups formed by the \"geo\" column, providing an estimate of the accuracy of\n",
    "    the imputation and returning the imputed data.\n",
    "    \n",
    "    Decision has been made because in this way prediction will take into cosnderation countries similarities.\n",
    "    \n",
    "    \n",
    "    Results:\n",
    "    - All imputed dataframes are combined into a single dataframe.\n",
    "    - The Root Mean Squared Error (RMSE) is calculated between the real and imputed values.\n",
    "    - A dataframe is created to compare the real and imputed values.    \n",
    "    ============\n",
    "    \n",
    "    Required:\n",
    "    - df: original dataframe\n",
    "    - col_to_test: column to use fo testing prediction\n",
    "    - geo_column: geo column in dataframe\n",
    "    - country_column: country column in dataframe\n",
    "    \n",
    "    ============\n",
    "    \n",
    "    NOTE: mice models used consider also outliers values, because our goal si to identify values that\n",
    "    could be consistent with period and country reference. Decision to consider outliers has been done\n",
    "    because outliers are not wrong values but correct one and second because if we remove potentially\n",
    "    value predicted in same outlier row will be not realistic.\n",
    "    '''\n",
    "    \n",
    "    df_geo_list = df[geo_column].unique()\n",
    "    \n",
    "    # If you have enough data, can also subgrouping by 'year', so it will give as reference the same period (probably more attendible)\n",
    "\n",
    "    # Lista per contenere i dataframe imputati\n",
    "    imputed_dfs = []\n",
    "    true_values_list = []\n",
    "    imputed_values_list = []\n",
    "\n",
    "    for geo_value in df_geo_list:\n",
    "        # Estrai il sottogruppo corrispondente al valore corrente di 'geo'\n",
    "        group = df[df[geo_column] == geo_value].copy()\n",
    "\n",
    "        # Seleziona una frazione dei dati noti da imputare\n",
    "        true_values = group.sample(frac=0.1)[col_to_test]\n",
    "        group.loc[true_values.index, col_to_test] = np.nan\n",
    "\n",
    "        # Rimuovi le categorie inutilizzate nelle colonne \"geo\" e \"country\"\n",
    "        group[geo_column] = group[geo_column].cat.remove_unused_categories()\n",
    "        group[country_column] = group[country_column].cat.remove_unused_categories()\n",
    "        \n",
    "        # --- MICE\n",
    "        \n",
    "        # Crea il kernel di imputazione\n",
    "        kds = ImputationKernel(group, random_state=4)\n",
    "        \n",
    "        # Manually application\n",
    "        kds.mice(iterations=5, n_estimators=50, device='gpu') # verbose=2\n",
    "        # ---\n",
    "        \n",
    "        # Tuning parameters\n",
    "#         optimal_parameters, losses = kds.tune_parameters(dataset=0, optimization_steps=10)\n",
    "#         kds.mice(1, variable_parameters=optimal_parameters)\n",
    "        # print(optimal_parameters)\n",
    "        # ---\n",
    "        \n",
    "        # Ottieni il dataframe imputato\n",
    "        df_imputed = kds.complete_data()\n",
    "        # ---\n",
    "        \n",
    "        # Ripristina le categorie originali se necessario\n",
    "        df_imputed[geo_column] = pd.Categorical(df_imputed[geo_column], categories=df[geo_column].unique())\n",
    "        df_imputed[country_column] = pd.Categorical(df_imputed[country_column], categories=df[country_column].unique())\n",
    "\n",
    "        # Aggiungi il dataframe imputato alla lista\n",
    "        imputed_dfs.append(df_imputed)\n",
    "\n",
    "        # Recupera i valori imputati\n",
    "        imputed_values = df_imputed.loc[true_values.index, col_to_test]\n",
    "\n",
    "        # Estendi le liste dei valori veri e imputati\n",
    "        true_values_list.extend(true_values)\n",
    "        imputed_values_list.extend(imputed_values)\n",
    "\n",
    "    # Combina i dataframe imputati in un unico dataframe\n",
    "    final_df = pd.concat(imputed_dfs)\n",
    "\n",
    "    # Calcola l'RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(true_values_list, imputed_values_list))\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "\n",
    "    # Crea un DataFrame con i valori reali e imputati\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'True Values': true_values_list,\n",
    "        'Imputed Values': imputed_values_list\n",
    "    })\n",
    "\n",
    "    # Visualizza il DataFrame di confronto\n",
    "    display(comparison_df)\n",
    "    \n",
    "    return final_df, rmse, comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, rmse, comparison_df = mice_forest_geo(df_test_rep,col_to_test='HICP(%)', geo_column='geo', country_column='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65509723",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot compare the distribution by data and data with imputation\n",
    "kds.plot_imputed_distributions(wspace=0.2,hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae942a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e249f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae243bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8080e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f3346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd1402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
